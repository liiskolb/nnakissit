{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was also surprised to see that the vast majority of Python DCGAN implementations online are incorrect. Either not using fractional-strided CONVs, not properly freezing training, or using the incorrect activation function at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "# from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_data = pickle.load(open(\"classroom.pkl\", \"rb\"), encoding='latin1')\n",
    "X_train = np.array(cl_data)\n",
    "X_train.shape\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_train-=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: 2./255 * x - 1)\n",
    "\n",
    "#test_datagen = ImageDataGenerator(preprocessing_function=lambda x: 2./255 * x - )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=2,\n",
    "        class_mode=None)\n",
    "\n",
    "#validation_generator = test_datagen.flow_from_directory(\n",
    "#        'data/validation',\n",
    "#        target_size=(150, 150),\n",
    "#        batch_size=32,\n",
    "#        class_mode='binary')\n",
    "\n",
    "#model.fit_generator(\n",
    "#        train_generator,\n",
    "#        steps_per_epoch=2000,\n",
    "#        epochs=50,\n",
    "#        validation_data=validation_generator,\n",
    "#        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating G...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(1024, (8, 8), strides=(1, 1), padding=\"valid\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(512, (8, 8), strides=(2, 2), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(256, (8, 8), strides=(2, 2), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(128, (8, 8), strides=(2, 2), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(3, (8, 8), strides=(1, 1), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:77: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (8, 8), strides=(2, 2), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 1024)        6554624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 512)       33554944  \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 256)       8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 64, 64, 128)       2097280   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 64, 64, 3)         24579     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 50,627,971\n",
      "Trainable params: 50,624,131\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "generating D...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:83: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "//anaconda/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (8, 8), strides=(2, 2), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (8, 8), strides=(2, 2), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (8, 8), strides=(4, 4), padding=\"same\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:123: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (2, 2), padding=\"valid\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:130: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"re..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2, 2, 1025)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 32, 32, 128)   24704       input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, 32, 32, 128)   0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, 32, 32, 1)     0           leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 32, 32, 129)   0           leaky_re_lu_5[0][0]              \n",
      "                                                                   lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 16, 16, 256)   2113792     merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 16, 16, 256)   1024        conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, 16, 16, 256)   0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 16, 16, 1)     0           leaky_re_lu_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 16, 16, 257)   0           leaky_re_lu_6[0][0]              \n",
      "                                                                   lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 8, 8, 512)     8421888     merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 8, 8, 512)     2048        conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, 8, 8, 512)     0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (None, 8, 8, 1)       0           leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 8, 8, 513)     0           leaky_re_lu_7[0][0]              \n",
      "                                                                   lambda_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 2, 2, 1024)    33620992    merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 2, 2, 1024)    4096        conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)        (None, 2, 2, 1024)    0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, 2, 2, 1)       0           leaky_re_lu_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 2, 2, 1025)    0           leaky_re_lu_8[0][0]              \n",
      "                                                                   lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 1, 1, 1)       4101        merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_exit (Activation)           (None, 1, 1, 1)       0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 1, 1, 1)       0           conv_exit[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)              (None, 1)             0           activation_12[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 44,192,645\n",
      "Trainable params: 44,189,061\n",
      "Non-trainable params: 3,584\n",
      "____________________________________________________________________________________________________\n",
      "generating GAN...\n",
      "other_parameter_updates for the models(mainly for batch norm):\n",
      "[[[], [<tf.Tensor 'model_4/batch_normalization_12/AssignMovingAvg:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_4/batch_normalization_12/AssignMovingAvg_1:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_4/batch_normalization_13/AssignMovingAvg:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_4/batch_normalization_13/AssignMovingAvg_1:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_4/batch_normalization_14/AssignMovingAvg:0' shape=(1024,) dtype=float32_ref>, <tf.Tensor 'model_4/batch_normalization_14/AssignMovingAvg_1:0' shape=(1024,) dtype=float32_ref>], [<tf.Tensor 'model_4_1/batch_normalization_12/AssignMovingAvg:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_4_1/batch_normalization_12/AssignMovingAvg_1:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_4_1/batch_normalization_13/AssignMovingAvg:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_4_1/batch_normalization_13/AssignMovingAvg_1:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_4_1/batch_normalization_14/AssignMovingAvg:0' shape=(1024,) dtype=float32_ref>, <tf.Tensor 'model_4_1/batch_normalization_14/AssignMovingAvg_1:0' shape=(1024,) dtype=float32_ref>]], [[], [<tf.Tensor 'model_3/batch_normalization_8/AssignMovingAvg:0' shape=(1024,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_8/AssignMovingAvg_1:0' shape=(1024,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_9/AssignMovingAvg:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_9/AssignMovingAvg_1:0' shape=(512,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_10/AssignMovingAvg:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_10/AssignMovingAvg_1:0' shape=(256,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_11/AssignMovingAvg:0' shape=(128,) dtype=float32_ref>, <tf.Tensor 'model_3/batch_normalization_11/AssignMovingAvg_1:0' shape=(128,) dtype=float32_ref>]]]\n",
      "Ready. enter r() to train\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2 #128\n",
    "nb_classes = 10\n",
    "nb_epoch = 1\n",
    "eps=1e-11\n",
    "\n",
    "zed = 100\n",
    "\n",
    "def cifar():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 32, 32\n",
    "    # the CIFAR10 images are RGB\n",
    "    img_channels = 3\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    X_train-=0.5\n",
    "    X_test-=0.5\n",
    "\n",
    "    return X_train,Y_train,X_test,Y_test\n",
    "\n",
    "#print('loading cifar...')\n",
    "#xt,yt,xv,yv = cifar()\n",
    "\n",
    "#print('loading data...')\n",
    "#xt = X_train\n",
    "\n",
    "\n",
    "def leaky_relu(i):\n",
    "    return LeakyReLU(.2)(i)\n",
    "\n",
    "def bn(i):\n",
    "    return BatchNormalization()(i)\n",
    "\n",
    "def gen2(): # generative network, 2\n",
    "    inp = Input(shape=(zed,))\n",
    "    i = inp\n",
    "    i = Reshape((1,1,zed))(i)\n",
    "\n",
    "    ngf=128 # nr of generator filters generated in first convolutional layer\n",
    "\n",
    "    def deconv(i,nop,kw,oh,ow,std=1,tail=True,bm='same'):\n",
    "        global batch_size\n",
    "        i = Deconvolution2D(nop,kw,kw,subsample=(std,std),border_mode=bm,output_shape=(batch_size,oh,ow,nop))(i)\n",
    "        if tail:\n",
    "            i = bn(i)\n",
    "            i = Activation('relu')(i)\n",
    "        return i\n",
    "\n",
    "    #i = deconv(i,nop=ngf*8,kw=4,oh=4,ow=4,std=1,bm='valid')\n",
    "    #i = deconv(i,nop=ngf*4,kw=4,oh=8,ow=8,std=2)\n",
    "    #i = deconv(i,nop=ngf*2,kw=4,oh=16,ow=16,std=2)\n",
    "    #i = deconv(i,nop=ngf*1,kw=4,oh=32,ow=32,std=2)\n",
    "    #i = deconv(i,nop=3,kw=4,oh=32,ow=32,std=1,tail=False) # out : 32x32\n",
    "    \n",
    "    i = deconv(i,nop=ngf*8,kw=8,oh=4,ow=4,std=1,bm='valid')\n",
    "    i = deconv(i,nop=ngf*4,kw=8,oh=8,ow=8,std=2)\n",
    "    i = deconv(i,nop=ngf*2,kw=8,oh=16,ow=16,std=2)\n",
    "    i = deconv(i,nop=ngf*1,kw=8,oh=32,ow=32,std=2)\n",
    "    i = deconv(i,nop=3,kw=8,oh=64,ow=64,std=1,tail=False) # out : 32x32\n",
    "    i = Activation('tanh')(i)\n",
    "\n",
    "    m = Model(input=inp,output=i)\n",
    "    return m\n",
    "\n",
    "def concat_diff(i): # batch discrimination - increase generation diversity.\n",
    "    # return i\n",
    "    bv = Lambda(lambda x:K.mean(K.abs(x[:] - K.mean(x,axis=0)),axis=-1,keepdims=True))(i)\n",
    "    i = merge([i,bv],mode='concat')\n",
    "    return i\n",
    "\n",
    "def dis2(): # discriminative network, 2\n",
    "    # inp = Input(shape=(None,None,3))\n",
    "    inp = Input(shape=(64,64,3))\n",
    "    i = inp\n",
    "\n",
    "    ndf=128\n",
    "\n",
    "    def conv(i,nop,kw,std=1,usebn=True,bm='same'):\n",
    "        i = Convolution2D(nop,kw,kw,border_mode=bm,subsample=(std,std))(i)\n",
    "        if usebn:\n",
    "            i = bn(i)\n",
    "        i = leaky_relu(i)\n",
    "        return i\n",
    "\n",
    "    #i = conv(i,ndf*1,4,std=2,usebn=False)\n",
    "    #i = concat_diff(i)\n",
    "    #i = conv(i,ndf*2,4,std=2)\n",
    "    #i = concat_diff(i)\n",
    "    #i = conv(i,ndf*4,4,std=2)\n",
    "    #i = concat_diff(i)\n",
    "    #i = conv(i,ndf*8,4,std=2)\n",
    "    #i = concat_diff(i)\n",
    "    \n",
    "    i = conv(i,ndf*1,8,std=2,usebn=False)\n",
    "    i = concat_diff(i)\n",
    "    i = conv(i,ndf*2,8,std=2)\n",
    "    i = concat_diff(i)\n",
    "    i = conv(i,ndf*4,8,std=2)\n",
    "    i = concat_diff(i)\n",
    "    i = conv(i,ndf*8,8,std=4)\n",
    "    i = concat_diff(i)\n",
    "\n",
    "    print(i.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    # 1x1\n",
    "    i = Convolution2D(1,2,2,border_mode='valid')(i)\n",
    "\n",
    "    i = Activation('linear',name='conv_exit')(i)\n",
    "    i = Activation('sigmoid')(i)\n",
    "\n",
    "    i = Reshape((1,))(i)\n",
    "\n",
    "    m = Model(input=inp,output=i)\n",
    "    return m\n",
    "\n",
    "print('generating G...')\n",
    "gm = gen2()\n",
    "gm.summary()\n",
    "\n",
    "print('generating D...')\n",
    "dm = dis2()\n",
    "dm.summary()\n",
    "\n",
    "def gan(g,d):\n",
    "    # initialize a GAN trainer\n",
    "\n",
    "    # this is the fastest way to train a GAN in Keras\n",
    "    # two models are updated simutaneously in one pass\n",
    "\n",
    "    noise = Input(shape=g.input_shape[1:])\n",
    "    real_data = Input(shape=d.input_shape[1:])\n",
    "\n",
    "    generated = g(noise)\n",
    "    gscore = d(generated)\n",
    "    rscore = d(real_data)\n",
    "\n",
    "    def log_eps(i):\n",
    "        return K.log(i+1e-11)\n",
    "\n",
    "    # single side label smoothing: replace 1.0 with 0.9\n",
    "    dloss = - K.mean(log_eps(1-gscore) + .1 * log_eps(1-rscore) + .9 * log_eps(rscore))\n",
    "    gloss = - K.mean(log_eps(gscore))\n",
    "\n",
    "    Adam = tf.train.AdamOptimizer\n",
    "\n",
    "    lr,b1 = 1e-4,.2 # otherwise won't converge.\n",
    "    optimizer = Adam(lr,beta1=b1)\n",
    "\n",
    "    grad_loss_wd = optimizer.compute_gradients(dloss, d.trainable_weights)\n",
    "    update_wd = optimizer.apply_gradients(grad_loss_wd)\n",
    "\n",
    "    grad_loss_wg = optimizer.compute_gradients(gloss, g.trainable_weights)\n",
    "    update_wg = optimizer.apply_gradients(grad_loss_wg)\n",
    "\n",
    "    def get_internal_updates(model):\n",
    "        # get all internal update ops (like moving averages) of a model\n",
    "        inbound_nodes = model.inbound_nodes\n",
    "        input_tensors = []\n",
    "        for ibn in inbound_nodes:\n",
    "            input_tensors+= ibn.input_tensors\n",
    "        updates = [model.get_updates_for(i) for i in input_tensors]\n",
    "        return updates\n",
    "\n",
    "    other_parameter_updates = [get_internal_updates(m) for m in [d,g]]\n",
    "    # those updates includes batch norm.\n",
    "\n",
    "    print('other_parameter_updates for the models(mainly for batch norm):')\n",
    "    print(other_parameter_updates)\n",
    "\n",
    "    train_step = [update_wd, update_wg, other_parameter_updates]\n",
    "    losses = [dloss,gloss]\n",
    "\n",
    "    learning_phase = K.learning_phase()\n",
    "\n",
    "    def gan_feed(sess,batch_image,z_input):\n",
    "        # actual GAN trainer\n",
    "        nonlocal train_step,losses,noise,real_data,learning_phase\n",
    "\n",
    "        res = sess.run([train_step,losses],feed_dict={\n",
    "        noise:z_input,\n",
    "        real_data:batch_image,\n",
    "        learning_phase:True,\n",
    "        # Keras layers needs to know whether\n",
    "        # this run is training or testring (you know, batch norm and dropout)\n",
    "        })\n",
    "\n",
    "        loss_values = res[1]\n",
    "        return loss_values #[dloss,gloss]\n",
    "\n",
    "    return gan_feed\n",
    "\n",
    "print('generating GAN...')\n",
    "gan_feed = gan(gm,dm)\n",
    "\n",
    "print('Ready. enter r() to train')\n",
    "\n",
    "\n",
    "\n",
    "def r(ep=10000,noise_level=.01):\n",
    "    sess = K.get_session()\n",
    "\n",
    "    #np.random.shuffle(xt)\n",
    "    #shuffled_cifar = xt\n",
    "    #length = len(shuffled_cifar)\n",
    "\n",
    "    \n",
    "        # here's a more \"manual\" example\n",
    "    for e in range(ep):\n",
    "        print('Epoch', e)\n",
    "        batches = 0\n",
    "        for x_batch in train_generator:\n",
    "            \n",
    "            z_input = np.random.normal(loc=0.,scale=1.,size=(batch_size,zed))\n",
    "\n",
    "            losses = gan_feed(sess,x_batch,z_input)\n",
    "            print('dloss:{:6.4f} gloss:{:6.4f}'.format(losses[0],losses[1]))            \n",
    "\n",
    "            batches += 1\n",
    "            if batches >= 2 / 2: # len(x_train) / 2\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "    \n",
    "    #for i in range(ep):\n",
    "    #    noise_level *= 0.99\n",
    "    #    print('---------------------------')\n",
    "    #    print('iter',i,'noise',noise_level)\n",
    "    #\n",
    "    #    # sample from cifar\n",
    "    #    j = i % int(length/batch_size)\n",
    "    #    minibatch = shuffled_cifar[j*batch_size:(j+1)*batch_size]\n",
    "    #    # minibatch += np.random.normal(loc=0.,scale=noise_level,size=subset_cifar.shape)\n",
    "    #\n",
    "    #    z_input = np.random.normal(loc=0.,scale=1.,size=(batch_size,zed))\n",
    "    #\n",
    "    #    # train for one step\n",
    "    #    losses = gan_feed(sess,minibatch,z_input)\n",
    "    #    print('dloss:{:6.4f} gloss:{:6.4f}'.format(losses[0],losses[1]))\n",
    "    #\n",
    "    #    if i==ep-1 or i % 10==0: pass #show()\n",
    "\n",
    "def autoscaler(img):\n",
    "    limit = 400.\n",
    "    # scales = [0.1,0.125,1./6.,0.2,0.25,1./3.,1./2.] + range(100)\n",
    "    scales = np.hstack([1./np.linspace(10,2,num=9), np.linspace(1,100,num=100)])\n",
    "\n",
    "    imgscale = limit/float(img.shape[0])\n",
    "    for s in scales:\n",
    "        if s>=imgscale:\n",
    "            imgscale=s\n",
    "            break\n",
    "\n",
    "    img = cv2.resize(img,dsize=(int(img.shape[1]*imgscale),int(img.shape[0]*imgscale)),interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return img,imgscale\n",
    "\n",
    "def flatten_multiple_image_into_image(arr):\n",
    "    import cv2\n",
    "    num,uh,uw,depth = arr.shape\n",
    "\n",
    "    patches = int(num+1)\n",
    "    height = int(math.sqrt(patches)*0.9)\n",
    "    width = int(patches/height+1)\n",
    "\n",
    "    img = np.zeros((height*uh+height, width*uw+width, 3),dtype='float32')\n",
    "\n",
    "    index = 0\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if index>=num-1:\n",
    "                break\n",
    "            channels = arr[index]\n",
    "            img[row*uh+row:row*uh+uh+row,col*uw+col:col*uw+uw+col,:] = channels\n",
    "            index+=1\n",
    "\n",
    "    img,imgscale = autoscaler(img)\n",
    "\n",
    "    return img,imgscale\n",
    "\n",
    "def show(save=False):\n",
    "    i = np.random.normal(loc=0.,scale=1.,size=(batch_size,zed))\n",
    "    gened = gm.predict([i])\n",
    "\n",
    "    gened *= 0.5\n",
    "    gened +=0.5\n",
    "\n",
    "    im,ims = flatten_multiple_image_into_image(gened)\n",
    "    #cv2.imshow('gened scale:'+str(ims),im)\n",
    "    #cv2.waitKey(1)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "    if save!=False:\n",
    "        cv2.imwrite(save,im*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "dloss:2.0878 gloss:3.7579\n",
      "Epoch 1\n",
      "dloss:2.0660 gloss:1.5966\n",
      "Epoch 2\n",
      "dloss:1.4340 gloss:24.2435\n",
      "Epoch 3\n",
      "dloss:1.6752 gloss:13.4873\n",
      "Epoch 4\n",
      "dloss:2.8064 gloss:6.6614\n",
      "Epoch 5\n",
      "dloss:27.8613 gloss:-0.0000\n",
      "Epoch 6\n",
      "dloss:27.8613 gloss:-0.0000\n",
      "Epoch 7\n",
      "dloss:27.8613 gloss:-0.0000\n",
      "Epoch 8\n",
      "dloss:27.8613 gloss:-0.0000\n",
      "Epoch 9\n",
      "dloss:27.8613 gloss:-0.0000\n"
     ]
    }
   ],
   "source": [
    "r(ep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAB3CAYAAAANSYv6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npVKpvORUQ1+pVCovOdXQVyqVykvO/w+IFng4Z4aQKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1233644e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
